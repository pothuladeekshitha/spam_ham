{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('spam.csv',encoding=\"cp437\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>v1</th>\n",
       "      <th>v2</th>\n",
       "      <th>Unnamed: 2</th>\n",
       "      <th>Unnamed: 3</th>\n",
       "      <th>Unnamed: 4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1938</th>\n",
       "      <td>ham</td>\n",
       "      <td>Excellent! Are you ready to moan and scream in...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3865</th>\n",
       "      <td>ham</td>\n",
       "      <td>Theoretically yeah, he could be able to come</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>646</th>\n",
       "      <td>ham</td>\n",
       "      <td>Do you mind if I ask what happened? You dont h...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>180</th>\n",
       "      <td>ham</td>\n",
       "      <td>You lifted my hopes with the offer of money. I...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1518</th>\n",
       "      <td>ham</td>\n",
       "      <td>Shall i ask one thing if you dont mistake me.</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       v1                                                 v2 Unnamed: 2  \\\n",
       "1938  ham  Excellent! Are you ready to moan and scream in...        NaN   \n",
       "3865  ham       Theoretically yeah, he could be able to come        NaN   \n",
       "646   ham  Do you mind if I ask what happened? You dont h...        NaN   \n",
       "180   ham  You lifted my hopes with the offer of money. I...        NaN   \n",
       "1518  ham      Shall i ask one thing if you dont mistake me.        NaN   \n",
       "\n",
       "     Unnamed: 3 Unnamed: 4  \n",
       "1938        NaN        NaN  \n",
       "3865        NaN        NaN  \n",
       "646         NaN        NaN  \n",
       "180         NaN        NaN  \n",
       "1518        NaN        NaN  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5572, 5)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Data cleaning\n",
    "# 2. EDA\n",
    "# 3. Text Preprocessing\n",
    "# 4. Model building\n",
    "# 5. Evaluation\n",
    "# 6. Improvement\n",
    "# 7. Website\n",
    "# 8. Deploy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 5572 entries, 0 to 5571\n",
      "Data columns (total 5 columns):\n",
      " #   Column      Non-Null Count  Dtype \n",
      "---  ------      --------------  ----- \n",
      " 0   v1          5572 non-null   object\n",
      " 1   v2          5572 non-null   object\n",
      " 2   Unnamed: 2  50 non-null     object\n",
      " 3   Unnamed: 3  12 non-null     object\n",
      " 4   Unnamed: 4  6 non-null      object\n",
      "dtypes: object(5)\n",
      "memory usage: 217.8+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop last 3 cols\n",
    "df.drop(columns=['Unnamed: 2','Unnamed: 3','Unnamed: 4'],inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>v1</th>\n",
       "      <th>v2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5463</th>\n",
       "      <td>ham</td>\n",
       "      <td>U GOIN OUT 2NITE?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1216</th>\n",
       "      <td>spam</td>\n",
       "      <td>You have 1 new voicemail. Please call 08719181...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3852</th>\n",
       "      <td>ham</td>\n",
       "      <td>Dont worry, 1 day very big lambu ji vl come..t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2925</th>\n",
       "      <td>ham</td>\n",
       "      <td>Im done. Just studyn in library</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3797</th>\n",
       "      <td>ham</td>\n",
       "      <td>Feb  &amp;lt;#&amp;gt;  is \\I LOVE U\\\" day. Send dis t...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        v1                                                 v2\n",
       "5463   ham                                  U GOIN OUT 2NITE?\n",
       "1216  spam  You have 1 new voicemail. Please call 08719181...\n",
       "3852   ham  Dont worry, 1 day very big lambu ji vl come..t...\n",
       "2925   ham                    Im done. Just studyn in library\n",
       "3797   ham  Feb  &lt;#&gt;  is \\I LOVE U\\\" day. Send dis t..."
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>target</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4515</th>\n",
       "      <td>spam</td>\n",
       "      <td>Congrats! 2 mobile 3G Videophones R yours. cal...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>ham</td>\n",
       "      <td>Wait that's still not all that clear, were you...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3871</th>\n",
       "      <td>ham</td>\n",
       "      <td>I am joining today formally.Pls keep praying.w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5340</th>\n",
       "      <td>ham</td>\n",
       "      <td>Are u awake? Is there snow there?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>566</th>\n",
       "      <td>ham</td>\n",
       "      <td>Oooh bed ridden ey? What are YOU thinking of?</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     target                                               text\n",
       "4515   spam  Congrats! 2 mobile 3G Videophones R yours. cal...\n",
       "30      ham  Wait that's still not all that clear, were you...\n",
       "3871    ham  I am joining today formally.Pls keep praying.w...\n",
       "5340    ham                  Are u awake? Is there snow there?\n",
       "566     ham      Oooh bed ridden ey? What are YOU thinking of?"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# renaming the cols\n",
    "df.rename(columns={'v1':'target','v2':'text'},inplace=True)\n",
    "df.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "encoder = LabelEncoder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['target'] = encoder.fit_transform(df['target'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>target</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   target                                               text\n",
       "0       0  Go until jurong point, crazy.. Available only ...\n",
       "1       0                      Ok lar... Joking wif u oni...\n",
       "2       1  Free entry in 2 a wkly comp to win FA Cup fina...\n",
       "3       0  U dun say so early hor... U c already then say...\n",
       "4       0  Nah I don't think he goes to usf, he lives aro..."
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "target    0\n",
       "text      0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# missing values\n",
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "403"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check for duplicate values\n",
    "df.duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove duplicates\n",
    "df = df.drop_duplicates(keep='first')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5169, 2)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>target</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   target                                               text\n",
       "0       0  Go until jurong point, crazy.. Available only ...\n",
       "1       0                      Ok lar... Joking wif u oni...\n",
       "2       1  Free entry in 2 a wkly comp to win FA Cup fina...\n",
       "3       0  U dun say so early hor... U c already then say...\n",
       "4       0  Nah I don't think he goes to usf, he lives aro..."
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    4516\n",
       "1     653\n",
       "Name: target, dtype: int64"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['target'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPAAAADnCAYAAAAghtuxAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAYA0lEQVR4nO3deZgU1b3G8e+ZfRg2WURZYimIKKKCCigoGJegFYNRE1ySG1Fzo0bjrpV4o6PRWJrE3SQ37hqzaMxVtBQwigtqcEEQFcGtjLIj2LLN9HT3uX9UAcM6PTPdfaq6f5/n6Ydhpqvq9XFe6lR11SmltUYIEU9lpgMIIdpOCixEjEmBhYgxKbAQMSYFFiLGpMBCxJgUWIgYkwILEWNSYCFiTAosRIxJgYWIMSmwEDEmBRYixqTAQsSYFFiIGJMCCxFjUmAhYkwKLESMSYGFiDEpsBAxJgUWIsakwELEmBRYiBiTAgsRY1JgIWJMCixEjEmBhYixCtMBRMssx+sE7AbsClhAT6DLNl7VQBJobPZa//d1wGLg881fvmuvLth/kMgZJQ83iw7L8cqB/YARwGBgT2AvoFcBNp8A5gGzgVnA28As37XXFWDboo2kwAZZjlcHjARGh6+RQEejoTaVAt4BZgDTgSm+a39pNpJoTgpcYJbj7QOcABwNDCVehzEZgjJ7wNO+a79tOE/JkwIXgOV4w4ATCYo70HCcXFoIPA1MAib7rt1kOE/JkQLnieV4g4HTCEq7q9k0BbEEeBC4x3fteabDlAopcA6FJ6G+A5wHHGY4jkmvAHcDj/quvcZ0mGImBc4By/G6A2cCZwO7GI4TJauAPwM3+q7tG85SlKTA7WA53kDgcuAUoMZwnChLAQ8Bv/Zd+yPTYYqJFLgNLMfbDbgS+AFQbjhOnKSBvwLX+a79gekwxUAK3AqW4/UCriIYLlcajhNnGeAfwJVywqt9pMBZCC+4uBi4lGhdaBF3TcAdwNW+aydMh4kjKXALLMezgT8A/UxnKWJLgZ8D9/muLb+QrSAF3gbL8XoCtwInm85SQl4GzvJd+33TQeJCCrwVluP9ALgZ6GE6SwlqAm4gGFanTIeJOilwM5bjfQP4I8F1ysKsGcApvmt/YjpIlMkN/SHL8U4A5iDljYoRwNuW451iOkiUlfwe2HK8CsAlOMssoulB4Kcy6cCWSrrAluPtBPwdONR0FtGiD4GTfdd+y3SQKCnZIbTleIcAM5HyxsXuwHTL8b5nOkiUlGSBLcc7H3ge2Nl0FtEqNcDfLce73HSQqCi5IbTleDcSXFEl4u1PBMfFJf1RU8kUOLxX90/A6aaziJyZDHzfd+1VpoOYUhIFthyvGvgbcJzpLCLn3gGO9l17oekgJhR9gcM5lScBYw1HEfkzHxjju/Zi00EKragLHM6UMQXY33QWkXdzgbG+ay81HaSQirbAluN1JjjTLOUtHXOAw0pp7uqi/BjJcrxa4EmkvKVmCPCs5XhdTQcplKIrcHhp5KPIBRqlaigwJRyBFb2iKzDwv4BtOoQwajjwhOV4RT/tUVEV2HK8euRzXhEYSzCTSlErmpNY4W1nD5vOISLnEt+1f2c6RL4URYHDx5jMAOpMZxGRkwGO8V17iukg+RD7AluO1xF4AxhkOouIrJXAAcU4u0cxHAPfjZRXbN8OwP9ZjtfBdJBci3WBLcc7D5hgOoeIhX2AojsWju0Q2nK8EcBLQJXpLCJWxhXT8XAsCxw+KWEOpfHcXZFbC4C9fdf+ynSQXIjrEPoapLyibfoQPM6lKMRuD2w53gHAv5GnAor2OdF37cdMh2ivWBU4vM75TWBf01lE7C0nGEovMR2kPeI2hL4EKa/IjR4UwVnp2OyBLccbQHDiqsZ0FlE0NDDSd+3XTQdpqzjtge9EyitySxE8xC62YlFgy/EOB44ynUMUpYMtx/u+6RBtFYsCA9eZDiCK2g3hzKWx02KBlVKWUurdQoTZGsvxxhM8qU6IfLGAC02HaItI74EtxysDrjWdQ5SEX4SzmMZKtgUuV0rdpZR6Tyk1VSlVq5T6sVLqDaXUbKXUY0qpDgBKqfuVUn9QSk1TSn2ilBqjlLpXKTVXKXV/K/OdAuzdymWEaItOwLmmQ7RWtgXeHbhTaz0Y+Ao4Afin1vpArfW+BHPyntHs/TsA3yQYljxJcKZvMDBEKbVfNhsM5zOqzzKfELlwbjijaWxkW+BPtdazwq/fIjhm2Fsp9bJSag5wKkFB13tSBx8wzwGWaK3naK0zwHvhstk4Ceif5XuFyIUewGmmQ7RGtgVubPZ1GqgA7gfO1VoPAa5m089o178/s9mymXDZbFyQ5fuEyKWLwnMvsdCeoJ2ARUqpSoI9cM5YjjcaGJbLdQqRpQHAd02HyFZ7CvxLgonkngU+yE2cDX6W4/UJ0RqxeX505K6FthyvF/A5UPSTcotIO9h37ddMh2hJFMf6pyPlFeadZjpANiK1B7YcTwEfI7NtCPMSwE6+azeYDrI9UdsDj0LKK6KhC3Cc6RAtiVqBjzcdQIhmcvrpSj5ErcCxOX0vSsJRUX/WcGQKbDne/mR/lZYQhVBFxHcqkSkwMnwW0XSi6QDbIwUWYvvGRPlB4dlel5xXluPtRR4fUPb1G4+zevZUUFDZ06LHMRew3LuZphVfAJBpWENZTR29J96+yXI6lWTxXy5Hp5ogk6HDHqPoekhwXmPZEze0uLwoCnUEE0pMNx1kayJRYOBb+VpxatVyvn7rSXqf8XvKKqtZ9rjLmrkv0XP85Rves+L5uymr3sqjhcsr6XXSrymrqkWnUyx++DJqd9uf6j6DslteFIsjiGiBozKEHpXXtWfS6FQSnUmjU42Ud+y24Udaa9Z+MJ26PQ/dYjGlFGVVwe2hOpOCTBqU2uQ921teFI3DTQfYlqjsgQ/O14orOvWg8/DvsuAPE1EVVdTsOpTaXTfe6NT4xXuU13WlslufrS6vM2kWPXABqZWL6DTMprr3Hpv8vKXlRVEYYTleR9+1V5sOsjnje2DL8XYFds7X+tMNq1n74Qz6nHUPfX/6ILqpkdXvTdvw8zXvv7jdvacqK6f3xNvpe879NC6aT3KZv8nPW1peFIVKIJL/k40XmDwPnxv8WVR06UV5hy6o8go6DDyIxgVzgWDvunb+a3QY1PL/m7KajtT0G8K6T2Zu+F5rlhexd5jpAFsThQLnbfgMUNG5J8mF88g0NaC1puGz2VR27wcE5a7s3peKzj22umx6bYJMQzBqyjQ10vBZ8P71WlpeFJWhpgNsTRSOgfO6B67uvQcd9hjFovsvQJWVUdWrP532HQfAmrkvbTH8Ta36ki8n30av711NevUKlns3g86AztBh0CF0GDB8w3u3trwoWpGcHdXo7YSW49UAa4jGSECIlvT0XXu56RDNmS5O/whkECJbkdsLmy7PAMPbF6I1hpgOsDkpsBDZkz3wZqTAIk6kwJuRAos42cV0gM1JgYXIXk/TATZn7GOk8B7LdUC5kQBCtE0337VXmg6xnsk9cHekvCJ+djQdoDmTBd7B4LaFaCspcEgKLOJIChyK9HSdQmyDFDgkc9CIOOrW8lsKx2SBOxjcthBtFakZKqXAQrROpD45MVlg0xeRCNEWUbiHfgOTYRoNbruo9WLF0mnVF6+sIRm5K4firpHKJCwzHWMDkwWO9HNX42wJ3XY8NnntuqlVlyXLld7JdJ5iUksyUiNHk2GkwHn0se6zyzHJ69eltVpqOkuRSZkO0JwUuIjN09/Y9dvJX6/KaBWdMV/8NZkO0JwUuMjN1bv0PzZ5bSKjVaTmcoqxSP3emizwOoPbLinv6V0HfDd59YqMVitMZykCi00HaM5kgdca3HbJma0HDDwxedXSjOYr01libpHpAM2ZLPBCg9suSTP1wEETklcu0pqE6SwxFqnfW5MFXkrEjidKwRt60J4nN13xhdZ8bTpLTMkeGMB3bQ18bmr7pezfmcGDf9j088+0ZpXpLDGzhvpEpP7hM/2h9H8Mb79kTc8MGTKx6bJPtWaN6SwxEqm9L0iBS9oLmf32ObPp4g+1lhOKWYrU8S9IgUvec5n99zur6YJ5WsvHelmQPfBmPjO8fQFMyQwfem7Tz97XWk4qtmCe6QCbM13g9w1vX4S8zMj9L2w6512t5S6x7XjLdIDNmS7wLCJ2bWkpezwz+oBLUz+ZrTVJ01ki6k3TATZn9PnAAJbjzSSiTz8vVSeVPz/j+oq7hynV/uljTn9iHU/NT7FjneLdczoCcOnUBp6cn6KqHPp3K+O+8bV0rVFbLPtVg+bMSet4d2kGpeDe79RwUL8Kfvl8A0/MS1GmYMc6xf3H1dK7U973RYuoT/TO90Zay/QeGOAN0wHEpv6W/uaIK1OnvaV1+2+dO22/Sib/YNPZk47sX8G759TxztkdGditjOtf3vqo/fzJDYwbUMEH53Zk9ll17NkzmM3m0lHVvHN2R2ad1ZFvD6zgmhcLMuqP3PAZpMBiGx5KHzXymtQP39CadHvWc+guFXSr3XTvelT/CirKgu+N7FvOF6syWyz3daPmpc9SnDE0GARUlasNe+nO1RvXtyYJW+678yKSBY7C/D5S4Ii6L330QRVkXv1FxcMjlMrPZG73zmpiwuAtfw0/WZmhZwfFxCcamL0kzf47l3PruBrqqoK6XvFcAw++00SXasW0HxVkfsRIFjgKe+D3kFsLI+uutH3wb1IT/q01W+4m2+m6lxqpKINTh2x5qJ3KwMxFGc4+oJK3f9KRukqFO33jUPm6w2v4/MJOnDqkkjteL8g5t8idwIIIFNh37RTwuukcYtt+nx4/6pbUCa9qTc7OeD4wK8lTH6Z4+PhalNpyENy3s6JvZ8WIvsHe+cS9Kpi5eMt/Q04ZUsljc/M+y83n1CcidxEHRKDAoammA4jtuzV9wug70+On56LEkz9KccMrSSadVEuHyq0fwe7UsYx+XcqYtzw4BH/u0xR79Qh+XT/8cuNh+aR5KQb1yPuv8VP53kBbGf8YCcByvGFE9BhDbMqp+MtLZ1U8dWi27z/5sbW84KdZvlbTq05x9dhqrp/eSGMautduPJH1x2/XsnBVhjMnNfD0qcEx7azFac6ctI5kGnbbIfi4aYdaxQmPrGXe8gxlCnbpWsYf7Rr6dM5ricdRn5iSzw20VVQKrAiuM+1lOoto2S8rHnrxjIpnxpjOUSCrgB7UJyJ5cUskhtDhvcGe6RwiO79K/XDMg6kjXzSdo0AmR7W8EJEChx43HUBk78rUxDF/TR1WCiV+wnSA7YlSgZ8FVpsOIbL389SPx/wjfegLpnPkUQp42nSI7YlMgX3XbkCG0bFzSdNZYyelD3rBdI48eZn6xErTIbYnMgUO3Ws6gGi9nzWdN/aZ9IHFOJyO/GFd1Ar8LOCbDiFa7+ymC8c8mx72gukcOZQE/mI6REsiVeDwbPQ9pnOItvlx0yVjp6X3fcF0jhz5J/WJyD+OJlIFDt0H7bsDRpgzsenysa+kBxfDcPpPpgNkI3IF9l17AfCM6Ryi7U5tumLMjMygOJd4PvWJaaZDZCNyBQ7dZTqAaJ8JySvHvJkZ+JLpHG10u+kA2YpqgT1kxsrYOzF51SGzMv1fNp2jlb4iOIzbLqVUnVLKU0rNVkq9q5SaoJTylVI3KKVeD18Dwvceq5SaoZR6Wyn1L6VUr/D79UqpB5RSU8Nlj1dK3aiUmqOUmqyUanFKo0gW2HftNHC96RyivZQ6LnnN6HczVpxKfA/1iWyeVjEOWKi13ldrvTcwOfz+11rr4cAdwC3h96YDI7XWQ4G/AZc1W09/wAbGA38GpmmthxDcI2+3FCKSBQ7dhzw7qQgodWzy2lEfZPpNN50kC01kP3yeAxwR7nEP0Vqvf+LjX5v9eVD4dV9gilJqDnApMLjZep7RWjeF6ytn4z8EcwCrpRCRLbDv2klkL1wUNGVlRyevP3h+ps8rprO04C7qE1kdummt5wP7ExTteqXUlet/1Pxt4Z+3A3eEe9afADXN3tMYri8DNOmNtwdmyGLKq8gWOHQP8IXpEKL9NGVl45I3jPwks/OrprNsw2rg6mzfrJTqDazVWv8Z+C0wLPzRhGZ/vhZ+3QVYEH79o/ZH3SjSBQ73wq7pHCI3MpSVH5m8cbif6fVay+8uuN9Rn1jaivcPAV5XSs0CrgCuDb9frZSaAZwPXBh+rx54VCn1MpDTi0MicUP/9liOVw18DPQxnUXkRgWppmlVF83sV7Z8hOksoSXAAOoT7bobTinlAwdorQt2BVek98AAvms3Av9jOofInRQVlYclbxq2QHePymSGv2pveU2JfIFDDxCcihdFIkVF5djGm/dbrHcwPS/4R+ToskmttVXIvS/EpMDhTQ7nQPsf9SGio4mKqkMbb9lnqe5ickLDK6hPxPYBe7EoMIDv2nOA20znELmVpLL60MZb9lquO880sPkXgUcNbDdnYlPg0FVsPB0vikQD1bWHNN46aIXuNKuAm10NTKQ+Ee2zuC2IVYF9114NXGQ6h8i9dVR3GN146+5f6brZBdrkJdQnPi3QtvIm8h8jbY3leB5wjOkcIvfqWLf61erzPu2i1g7J42amUp/4Vh7XXzCx2gM3cwawzHQIkXtrqO04qvG2XVbp2vfytIkEwe9PUYhlgX3XXgycbjqHyI/VdOh8cONtfVfrmvfzsPrzqU8UzeW5sSwwgO/aTwF3ms4h8mMVdV1GNd7We62u/iCHq51EfeKBHK7PuNgWOHQxYOLjB1EACTp2Pbjxtl5rddW8HKxuIfDfOVhPpMS6wOFllt8HvjadReTHV3TaYXTjrT0adOWH7VjNOmA89YklucoVFbEuMIDv2h8T3KKV8yfIi2hYQZfuoxtv7dqgKz9uw+IaOI36xJu5zhUFsS8wgO/ajxPMdCCK1HK69hzTeHOnRl3R2s9ur6E+8UheQkVAURQYwHftm4jRbIKi9ZbQbcexjTfXJnWFn+Uij9CKm/TjqGgKHLqAiD8OUrTPIrrvNLbxpuomXd7S1DdvEgyd43elUivE8kqs7bEcrxaYBkTlZnGRB33VsoXTqi5KV6p0v638eCFwIPWJhYXOVWjFtgfGd+11wLHAJ6aziPz5QvfsfXjytyqlyza/uWU5MK4UygtFWGAA37WXAUcgTzosav/RvfoembwxndJli8JvrQCOoD4xx2SuQiq6IXRzluP1A54DdjedReRPf7Xgs8lVTkOlSp9MfeJt03kKqagLDGA53k4EJd7LdBaRN1/W0njkXPf4kiovlECBASzH6wlMBfYznUXk3GLgCN+183X3UqQV5THw5sJj4m8CUZkFUeSGDxxSquWFEikwgO/aK4EjgadNZxE58TIw3Hftj0wHMalkCgzgu/bXBB8xydMe4u0egmFzyU/qUBLHwFtjOd5JBL8IHUxnEVlLA5f4rn1Li+8sESVbYADL8YYCjwPfMJ1FtCgBTPBde4rpIFFSUkPozfmu/TZwAMH8wCK63gFGSHm3VNIFhg1nqA8nmHNanvwQLRngBuBA37VzMStH0SnpIfTmLMcbDjwEDDSdRfAp8F++a8szsbaj5PfAzfmu/TowFLgFmeHDpHuAfaS8LZM98DZYjncQcC8wyHSWErIQONt37Ummg8SF7IG3wXft1wguvfw5Mmlevq0jeML9QClv68geOAuW4+0I1BNMS1puNk3R+Ttwme/a/zEdJI6kwK1gOd6ewG8A23SWIvAmcIHv2q+YDhJnUuA2sBzvcOBGYJjpLDE0j2C4/HD44HbRDlLgdrAc7wjgEqAonnSXZ7OB64DHfNeWM/w5IgXOAcvx9iZ4zMspQJXhOFEzBbjJd+2ppoMUIylwDlmOtzNwHsHJru6G45i0kuDk1B2lfK9uIUiB88ByvEqCYfUpwHeAOrOJCiIJeARXsnm+aycN5ykJUuA8sxyvDhhPUOajgEqziXLuVYLSPuK79grTYUqNFLiALMfrTlDmbxHcQBHHYfYygkkCnwWe9V37c8N5SpoU2BDL8coIPoY6DDgUGA10NRpq69YRTF/zL4LSzpaPf6JDChwRYaH3AoYAg5u9+lO4S16/ILj3dv1rDvCB79pym2VESYEjznK8GoIbKgYD/YAeQM9mr/V/39qJMh2+MgQzWiwPX8sIbhxYEL4+BeaEE/+JGJECFwnL8dZfo52RIW7pkAILEWNyO6EQMSYFFiLGpMBCxJgUWIgYkwILEWNSYCFiTAosRIxJgYWIMSmwEDEmBRYixqTAQsSYFFiIGJMCCxFjUmAhYkwKLESMSYGFiDEpsBAxJgUWIsakwELEmBRYiBiTAgsRY1JgIWJMCixEjEmBhYgxKbAQMSYFFiLGpMBCxNj/A4EpTa14gbaYAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.pie(df['target'].value_counts(), labels=['ham','spam'],autopct=\"%0.2f\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data is imbalanced"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['num_characters'] = df['text'].apply(len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# num of words\n",
    "df['num_words'] = df['text'].apply(lambda x:len(nltk.word_tokenize(x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['num_sentences'] = df['text'].apply(lambda x:len(nltk.sent_tokenize(x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[['num_characters','num_words','num_sentences']].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ham\n",
    "df[df['target'] == 0][['num_characters','num_words','num_sentences']].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#spam\n",
    "df[df['target'] == 1][['num_characters','num_words','num_sentences']].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install -U seaborn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total = len(df)\n",
    "plt.figure(figsize = (5, 5))\n",
    "plt.title(\"Number of spam vs ham messages\")\n",
    "ax = sns.countplot(x = 'target', data = df)\n",
    "for p in ax.patches:\n",
    "    percentage = '{0:.0f}%'.format(p.get_height() / total * 100)\n",
    "    x = p.get_x() + p.get_width() / 2\n",
    "    y = p.get_height() + 20\n",
    "    ax.annotate(percentage, (x, y), ha = 'center')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.figure(figsize=(12,6))\n",
    "# sns.histplot(df[df['target'] == 0]['num_words'])\n",
    "# sns.histplot(df[df['target'] == 1]['num_words'],color='red')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.pairplot(df,hue='target')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.heatmap(df.corr(),annot=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Data Preprocessing\n",
    "- Lower case\n",
    "- Tokenization\n",
    "- Removing special characters\n",
    "- Removing stop words and punctuation\n",
    "- Stemming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('omw-1.4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import PorterStemmer\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.tokenize import word_tokenize\n",
    " \n",
    "ps = PorterStemmer()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "print(string.punctuation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_text(text):\n",
    "    text = text.lower()\n",
    "    text = nltk.word_tokenize(text)\n",
    "    \n",
    "    y = []\n",
    "    for i in text:\n",
    "        if i.isalnum():\n",
    "            y.append(i)\n",
    "    \n",
    "    text = y[:]\n",
    "    y.clear()\n",
    "    \n",
    "    for i in text:\n",
    "        if i not in stopwords.words('english') and i not in string.punctuation:\n",
    "            y.append(i)\n",
    "            \n",
    "    text = y[:]\n",
    "    y.clear()\n",
    "    \n",
    "    for i in text:\n",
    "        y.append(ps.stem(i))\n",
    "    \n",
    "            \n",
    "    return \" \".join(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform_text(\"I'm gonna be home soon and i don't want to talk about this stuff anymore tonight, k? I've cried enough today.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['text'][10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem.porter import PorterStemmer\n",
    "ps = PorterStemmer()\n",
    "ps.stem('loving')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['transformed_text'] = df['text'].apply(transform_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install wordcloud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from wordcloud import WordCloud\n",
    "wc = WordCloud(width=500,height=500,min_font_size=10,background_color='white')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spam_wc = wc.generate(df[df['target'] == 1]['transformed_text'].str.cat(sep=\" \"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15,6))\n",
    "plt.imshow(spam_wc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ham_wc = wc.generate(df[df['target'] == 0]['transformed_text'].str.cat(sep=\" \"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15,6))\n",
    "plt.imshow(ham_wc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spam_corpus = []\n",
    "for msg in df[df['target'] == 1]['transformed_text'].tolist():\n",
    "    for word in msg.split():\n",
    "        spam_corpus.append(word)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(spam_corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "sns.barplot(pd.DataFrame(Counter(spam_corpus).most_common(30))[0],pd.DataFrame(Counter(spam_corpus).most_common(30))[1])\n",
    "plt.xticks(rotation='vertical')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ham_corpus = []\n",
    "for msg in df[df['target'] == 0]['transformed_text'].tolist():\n",
    "    for word in msg.split():\n",
    "        ham_corpus.append(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(ham_corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "sns.barplot(pd.DataFrame(Counter(ham_corpus).most_common(30))[0],pd.DataFrame(Counter(ham_corpus).most_common(30))[1])\n",
    "plt.xticks(rotation='vertical')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Text Vectorization\n",
    "# using Bag of Words\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Model Building"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer,TfidfVectorizer\n",
    "cv = CountVectorizer()\n",
    "tfidf = TfidfVectorizer(max_features=3000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = tfidf.fit_transform(df['transformed_text']).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from sklearn.preprocessing import MinMaxScaler\n",
    "#scaler = MinMaxScaler()\n",
    "#X = scaler.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# appending the num_character col to X\n",
    "#X = np.hstack((X,df['num_characters'].values.reshape(-1,1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df['target'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train,X_test,y_train,y_test = train_test_split(X,y,test_size=0.2,random_state=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import GaussianNB,MultinomialNB,BernoulliNB\n",
    "from sklearn.metrics import accuracy_score,confusion_matrix,precision_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gnb = GaussianNB()\n",
    "mnb = MultinomialNB()\n",
    "bnb = BernoulliNB()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gnb.fit(X_train,y_train)\n",
    "y_pred1 = gnb.predict(X_test)\n",
    "print(accuracy_score(y_test,y_pred1))\n",
    "print(confusion_matrix(y_test,y_pred1))\n",
    "print(precision_score(y_test,y_pred1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnb.fit(X_train,y_train)\n",
    "y_pred2 = mnb.predict(X_test)\n",
    "print(accuracy_score(y_test,y_pred2))\n",
    "print(confusion_matrix(y_test,y_pred2))\n",
    "print(precision_score(y_test,y_pred2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bnb.fit(X_train,y_train)\n",
    "y_pred3 = bnb.predict(X_test)\n",
    "print(accuracy_score(y_test,y_pred3))\n",
    "print(confusion_matrix(y_test,y_pred3))\n",
    "print(precision_score(y_test,y_pred3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tfidf --> MNB\n",
    "!pip install xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from xgboost import XGBClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svc = SVC(kernel='sigmoid', gamma=1.0)\n",
    "knc = KNeighborsClassifier()\n",
    "mnb = MultinomialNB()\n",
    "dtc = DecisionTreeClassifier(max_depth=5)\n",
    "lrc = LogisticRegression(solver='liblinear', penalty='l1')\n",
    "rfc = RandomForestClassifier(n_estimators=50, random_state=2)\n",
    "abc = AdaBoostClassifier(n_estimators=50, random_state=2)\n",
    "bc = BaggingClassifier(n_estimators=50, random_state=2)\n",
    "etc = ExtraTreesClassifier(n_estimators=50, random_state=2)\n",
    "gbdt = GradientBoostingClassifier(n_estimators=50,random_state=2)\n",
    "xgb = XGBClassifier(n_estimators=50,random_state=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clfs = {\n",
    "    'SVC' : svc,\n",
    "    'KN' : knc, \n",
    "    'NB': mnb, \n",
    "    'DT': dtc, \n",
    "    'LR': lrc, \n",
    "    'RF': rfc, \n",
    "    'AdaBoost': abc, \n",
    "    'BgC': bc, \n",
    "    'ETC': etc,\n",
    "    'GBDT':gbdt,\n",
    "    'xgb':xgb\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_classifier(clf,X_train,y_train,X_test,y_test):\n",
    "    clf.fit(X_train,y_train)\n",
    "    y_pred = clf.predict(X_test)\n",
    "    accuracy = accuracy_score(y_test,y_pred)\n",
    "    precision = precision_score(y_test,y_pred)\n",
    "    \n",
    "    return accuracy,precision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_classifier(svc,X_train,y_train,X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_scores = []\n",
    "precision_scores = []\n",
    "\n",
    "for name,clf in clfs.items():\n",
    "    \n",
    "    current_accuracy,current_precision = train_classifier(clf, X_train,y_train,X_test,y_test)\n",
    "    \n",
    "    print(\"For \",name)\n",
    "    print(\"Accuracy - \",current_accuracy)\n",
    "    print(\"Precision - \",current_precision)\n",
    "    \n",
    "    accuracy_scores.append(current_accuracy)\n",
    "    precision_scores.append(current_precision)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = list(clfs.keys())\n",
    "#df['Algorithm'] = a\n",
    "#for i in range(0,len(a)):\n",
    "performance_df = pd.DataFrame({'Algorithm':a,'Accuracy':accuracy_scores,'Precision':precision_scores}).sort_values('Precision',ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "performance_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "performance_df1 = pd.melt(performance_df, id_vars = \"Algorithm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "performance_df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.catplot(x = 'Algorithm', y='value', \n",
    "               hue = 'variable',data=performance_df1, kind='bar',height=5)\n",
    "plt.ylim(0.5,1.0)\n",
    "plt.xticks(rotation='vertical')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model improve\n",
    "# 1. Change the max_features parameter of TfIdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_df = pd.DataFrame({'Algorithm':a,'Accuracy_max_ft_3000':accuracy_scores,'Precision_max_ft_3000':precision_scores}).sort_values('Precision_max_ft_3000',ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_df = pd.DataFrame({'Algorithm':a,'Accuracy_scaling':accuracy_scores,'Precision_scaling':precision_scores}).sort_values('Precision_scaling',ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df = performance_df.merge(temp_df,on='Algorithm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df_scaled = new_df.merge(temp_df,on='Algorithm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_df = pd.DataFrame({'Algorithm':a,'Accuracy_num_chars':accuracy_scores,'Precision_num_chars':precision_scores}).sort_values('Precision_num_chars',ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df_scaled.merge(temp_df,on='Algorithm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Voting Classifier\n",
    "svc = SVC(kernel='sigmoid', gamma=1.0,probability=True)\n",
    "mnb = MultinomialNB()\n",
    "etc = ExtraTreesClassifier(n_estimators=50, random_state=2)\n",
    "\n",
    "from sklearn.ensemble import VotingClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "voting = VotingClassifier(estimators=[('svm', svc), ('nb', mnb), ('et', etc)],voting='soft')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "voting.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = voting.predict(X_test)\n",
    "print(\"Accuracy\",accuracy_score(y_test,y_pred))\n",
    "print(\"Precision\",precision_score(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Applying stacking\n",
    "estimators=[('svm', svc), ('nb', mnb), ('et', etc)]\n",
    "final_estimator=RandomForestClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import StackingClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = StackingClassifier(estimators=estimators, final_estimator=final_estimator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf.fit(X_train,y_train)\n",
    "y_pred = clf.predict(X_test)\n",
    "print(\"Accuracy\",accuracy_score(y_test,y_pred))\n",
    "print(\"Precision\",precision_score(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "pickle.dump(tfidf,open('vectorizer.pkl','wb'))\n",
    "pickle.dump(mnb,open('model.pkl','wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
